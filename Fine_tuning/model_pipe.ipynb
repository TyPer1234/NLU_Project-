{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4762974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c250a6",
   "metadata": {},
   "source": [
    "# 1.) Basic EDA of csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa768e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PrimaryVPHostileLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0781f88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>year</th>\n",
       "      <th>hostility_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senator J.D. Vance (R-OH) andGovernor Tim Walz...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good evening. I'm Norah O'Donnell and thank yo...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm Margaret Brennan. In order to have a thoug...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you, Norah. Earlier today, Iran launched...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, thank you. And thank you for those joini...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement     debate_id  year  \\\n",
       "0  Senator J.D. Vance (R-OH) andGovernor Tim Walz...  2024_VP_1001  2024   \n",
       "1  Good evening. I'm Norah O'Donnell and thank yo...  2024_VP_1001  2024   \n",
       "2  I'm Margaret Brennan. In order to have a thoug...  2024_VP_1001  2024   \n",
       "3  Thank you, Norah. Earlier today, Iran launched...  2024_VP_1001  2024   \n",
       "4  Well, thank you. And thank you for those joini...  2024_VP_1001  2024   \n",
       "\n",
       "   hostility_label  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              1.0  \n",
       "4              1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22501b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['hostility_label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9fcf0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c025ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>debate_id</th>\n",
       "      <th>year</th>\n",
       "      <th>hostility_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senator J.D. Vance (R-OH) andGovernor Tim Walz...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good evening. I'm Norah O'Donnell and thank yo...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm Margaret Brennan. In order to have a thoug...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you, Norah. Earlier today, Iran launched...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, thank you. And thank you for those joini...</td>\n",
       "      <td>2024_VP_1001</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement     debate_id  year  \\\n",
       "0  Senator J.D. Vance (R-OH) andGovernor Tim Walz...  2024_VP_1001  2024   \n",
       "1  Good evening. I'm Norah O'Donnell and thank yo...  2024_VP_1001  2024   \n",
       "2  I'm Margaret Brennan. In order to have a thoug...  2024_VP_1001  2024   \n",
       "3  Thank you, Norah. Earlier today, Iran launched...  2024_VP_1001  2024   \n",
       "4  Well, thank you. And thank you for those joini...  2024_VP_1001  2024   \n",
       "\n",
       "   hostility_label  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              1.0  \n",
       "4              1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be54be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the hostility labels into int values\n",
    "\n",
    "df['hostility_label'] = df['hostility_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832fec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['statement', 'hostility_label'],\n",
      "    num_rows: 5865\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "statements_df = Dataset.from_pandas(df)\n",
    "\n",
    "statements_df = statements_df.remove_columns(['debate_id','year','__index_level_0__'])\n",
    "\n",
    "print(statements_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec9db3",
   "metadata": {},
   "source": [
    "# Hate BERT Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5168692",
   "metadata": {},
   "source": [
    "## Model tokenization for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ccbc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7485fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2023, 2003, 2019, 2742, 4861, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Test a sample tokenization\n",
    "test = hb_tokenizer(\"This is an example statement.\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f7bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Tokenization Function\n",
    "def tokenization_function(examples, tokenizer):\n",
    "    return tokenizer(\n",
    "        examples[\"statement\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8336d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/5865 [00:00<?, ? examples/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 5865/5865 [00:00<00:00, 8210.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = statements_df.map(lambda x: tokenization_function(x, hb_tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43b6e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "hb_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"GroNLP/hateBERT\",\n",
    "    num_labels=2    # Important! 2 classes: hate, not hate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce984014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hb_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62222edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['statement', 'hostility_label'],\n",
      "    num_rows: 4692\n",
      "})\n",
      "Dataset({\n",
      "    features: ['statement', 'hostility_label'],\n",
      "    num_rows: 1173\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split dataset train/val\n",
    "train_test_split = statements_df.train_test_split(test_size=0.2, seed=1)\n",
    "\n",
    "train_dataset = train_test_split['train']\n",
    "val_dataset = train_test_split['test']\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5e29923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/hatebert_finetuned\",           \n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy='epoch' ,  \n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./output/logs\", \n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True, \n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    save_total_limit=2, \n",
    "    report_to=\"none\",\n",
    "    use_mps_device=True, ##### only add this if running locally,\n",
    "    disable_tqdm=False # progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5085dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "accuracy_metric = load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67acf60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['statement', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 5865\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives an error in the hostility label so renaming\n",
    "\n",
    "#tokenized_dataset = tokenized_dataset.rename_column(\"hostility_label\", \"labels\")\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dfe3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=1)\n",
    "\n",
    "train_dataset = train_test_split['train']\n",
    "val_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02d46635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=hb_model,\n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=val_dataset,     \n",
    "    compute_metrics=compute_metrics,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf2ccb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "##trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2181ac2",
   "metadata": {},
   "source": [
    "# ROBERTA Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3a6a2",
   "metadata": {},
   "source": [
    "## Model Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c15d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_tokenizer = AutoTokenizer.from_pretrained(\"facebook/roberta-hate-speech-dynabench-r4-target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee837a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
